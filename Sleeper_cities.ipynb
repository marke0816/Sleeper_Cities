{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyMongo if necesary on computer \n",
    "#pip install pymongo\n",
    "\n",
    "# if receiving error message install \"dnspython\"\n",
    "#!pip install dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from path import Path\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from config import db_user, db_password\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check version of Pymongo\n",
    "import pymongo\n",
    "print(\"version:\",pymongo.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataframe from MongoDB using Pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Pymongo Connection\n",
    "conn = f\"mongodb+srv://{db_user}:{db_password}@cluster0.f7wzt.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Create data base\n",
    "db = client.sleeper_cities\n",
    "# assign Mongo collection to a variable \n",
    "housing_mongo = db.housing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Create a new collection/table for each CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the collection/table from MongoDB.  \n",
    "response = housing_mongo.find()\n",
    "# Transforming it into a Dataframe\n",
    "housing_panda_df = pd.DataFrame(list(response))\n",
    "#Show the dataframe \n",
    "housing_panda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Imported dataframe has \"_id\" column from MongoDB indexing. Needs to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Housing_data.csv dataset.\n",
    "file_path = \"Resources/housing_data_cleaned.csv\"\n",
    "housing_df = pd.read_csv(file_path)\n",
    "print(housing_df.shape)\n",
    "housing_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to a datetime column\n",
    "housing_df[\"date\"] = pd.to_datetime(housing_df[\"date\"])\n",
    "housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new DataFrame\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column.\n",
    "housing_df[\"year\"] = pd.DatetimeIndex(housing_df['date']).year\n",
    "housing_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to show only data from 2019\n",
    "housing_df_filtered = housing_df[housing_df['year'] == 2019]\n",
    "print(housing_df_filtered.shape)\n",
    "housing_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by metro_area/city - index split separately \n",
    "grouped_housing_df = housing_df_filtered.groupby(['metro_area/city'],axis=0,as_index=False).mean()\n",
    "grouped_housing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check types\n",
    "grouped_housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with DF cities  \n",
    "metro_name_df = pd.DataFrame(grouped_housing_df['metro_area/city'])\n",
    "print(metro_name_df.shape)\n",
    "metro_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new DF with columns needed for ML - Drop: (year, price red, price inc, pending listing)\n",
    "ml_housing_df= grouped_housing_df[['median_listing_price','active_listing_count','median_days_on_market','new_listing_count','average_listing_price','total_listing_count']]\n",
    "print(ml_housing_df.shape)\n",
    "ml_housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with StandardScaler().\n",
    "X_scaled = StandardScaler().fit_transform(ml_housing_df)\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to three principal components.\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three principal components.\n",
    "pcs_df = pd.DataFrame(X_pca, columns=['PC 1','PC 2', 'PC 3'])\n",
    "pcs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the elbow curve\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the NeasrestNeighbors model.\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "\n",
    "# Fit the model\n",
    "neigh.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "NearestNeighbors(n_neighbors=5)\n",
    "A = neigh.kneighbors_graph(pcs_df)\n",
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame including predicted clusters and cryptocurrencies features.\n",
    "# Concatentate the crypto_df and pcs_df DataFrames on the same columns.\n",
    "clustered_df = ml_housing_df.join(pcs_df, how='inner')\n",
    "\n",
    "#  Add a new column, \"CoinName\" to the clustered_df DataFrame that holds the names of the cryptocurrencies. \n",
    "clustered_df = clustered_df.join(metro_name_df, how='inner')\n",
    "\n",
    "#  Add a new column, \"Class\" to the clustered_df DataFrame that holds the predictions.\n",
    "# Add the predicted class columns\n",
    "clustered_df[\"Class\"] = neigh.labels_\n",
    "clustered_df.head(10)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model.\n",
    "model = KMeans(n_clusters=5, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "prediction = model.predict(pcs_df)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame including predicted clusters and cryptocurrencies features.\n",
    "# Concatentate the crypto_df and pcs_df DataFrames on the same columns.\n",
    "clustered_k_df = ml_housing_df.join(pcs_df, how='inner')\n",
    "\n",
    "#  Add a new column, \"CoinName\" to the clustered_df DataFrame that holds the names of the cryptocurrencies. \n",
    "clustered_k_df = clustered_k_df.join(metro_name_df, how='inner')\n",
    "\n",
    "#  Add a new column, \"Class\" to the clustered_df DataFrame that holds the predictions.\n",
    "# Add the predicted class columns\n",
    "clustered_k_df[\"Class\"] = model.labels_\n",
    "clustered_k_df.head(10)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_k_df.shape)\n",
    "clustered_k_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Austin metro area \n",
    "clustered_k_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model.\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "\n",
    "# Fit the model\n",
    "neigh.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "NearestNeighbors(n_neighbors=5)\n",
    "A = neigh.kneighbors_graph(pcs_df)\n",
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 3D-Scatter with the PCA data and the clusters\n",
    "# Plot\n",
    "fig = px.scatter_3d(clustered_k_df, x=\"PC 1\", y=\"PC 2\", z=\"PC 3\", color=\"Class\", symbol=\"Class\", width=800, hover_name=\"metro_area/city\", hover_data=[\"average_listing_price\"])\n",
    "fig.update_layout(legend=dict(x=0,y=1))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D scatter plot\n",
    "clustered_k_df.hvplot.scatter(\n",
    "    x=\"PC 1\",\n",
    "    y=\"PC 2\",\n",
    "    hover_cols=[\"metro_area/city\"],\n",
    "    by=\"Class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
